{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Yiv1OaYJJ7-"
   },
   "source": [
    "# Question 1 Chunkify\n",
    "You have a file that needs to be divided into n chunks. While it would be straightforward to split the file into equal-bytes sizes and then write those chunks to file, you cannot write any incomplete lines to the files. This means that all of the n files that you create must have no truncated lines. If a split of a certain byte-size would result in a truncated line, then you can back off and only write the previous complete line. You can save the rest of it for the next chunk.\n",
    "\n",
    "You can download Metamorphosis, by Franz Kafka as the sample text. The file is of size 139055 bytes. Splitting into three pieces gives the following files and their respective sizes:\n",
    "\n",
    "size\tfilename\n",
    "46310\tpg5200.txt_000.txt\n",
    "46334\tpg5200.txt_001.txt\n",
    "46411\tpg5200.txt_002.txt\n",
    "The last line of the pg5200.txt_000.txt is the following:\n",
    "\n",
    "her, she hurried out again and even turned the key in the lock so\n",
    "\n",
    "The last line of the pg5200.txt_001.txt is the following:\n",
    "\n",
    "there.  He, fortunately, would usually see no more than the object\n",
    "\n",
    "As a final hint, splitting the same file into eight parts gives the following:\n",
    "\n",
    "size\tfilename\n",
    "17321\tpg5200.txt_000.txt\n",
    "17376\tpg5200.txt_001.txt\n",
    "17409\tpg5200.txt_002.txt\n",
    "17354\tpg5200.txt_003.txt\n",
    "17445\tpg5200.txt_004.txt\n",
    "17332\tpg5200.txt_005.txt\n",
    "17381\tpg5200.txt_006.txt\n",
    "17437\tpg5200.txt_007.txt\n",
    "You should think about making your file sizes as uniform as possible (this not graded, however). Otherwise, for a very long file, the last file may be inordinately large, as compared to the others. Your algorithm should pass through the file exactly once. You should assume that you cannot read the entire file into memory at once. If possible, you also want to minimize how much you move the file pointer around in the file. You should ensure that your code produces the file sizes that are indicated for each of the cases shown above.\n",
    "\n",
    "Here is the function signature:\n",
    "```\n",
    "def split_by_n(fname,n=3):\n",
    "    '''\n",
    "    Split files into sub files of near same size\n",
    "    fname : Input file name\n",
    "    n is the number of segments\n",
    "    '''\n",
    "```\n",
    "Hint: Use wt as the file write mode.\n",
    "The individual filenames should include the original filename (fname) and a number indicating the current file sequence number in the split. For example, if pg5200.txt is the original file then the 8th division should be named pg5200.txt_007.txt. Your code should strive to produce file sizes as close to the file sizes shown in the example above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5icTxDHJJ8H"
   },
   "source": [
    "**Validation Tests** <br>\n",
    "Check for corner cases and constraints in the inputs enlist all cases used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqyBHstzJJ8I"
   },
   "outputs": [],
   "source": [
    "assert isinstance(fname, str), \"fname must be a str\"\n",
    "assert isinstance(n, int), \"n must be an int\"\n",
    "assert len(fname) > 0, \"fname must not be empty\"\n",
    "assert n > 0, \"n must be positive\"\n",
    "assert os.path.exists(fname) and os.path.isfile(fname), \"file must exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oFjVnLvJJ8J"
   },
   "source": [
    "**Functional Tests** <br>\n",
    "Check function output matches expected result enlist all cases used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoRt-r5FJJ8K"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "fname = \"./pg5200.txt\"\n",
    "ns = [1,2,3,5,8,10,100]\n",
    "for n in ns:\n",
    "  split_by_n(fname,n)\n",
    "  for i in range(n):\n",
    "      file_name = fname + \"_\" + str(i).zfill(3)+\".txt\"\n",
    "      assert os.path.exists(file_name)\n",
    "  \"checking for file existent\"\n",
    "\n",
    "  # check last line in chunks present in main file\n",
    "  with open(fname, 'r') as f:\n",
    "      all_lines = f.readlines()[-1]\n",
    "  for i in range(n):\n",
    "      file_name = fname + \"_\" + str(i).zfill(3)+\".txt\"\n",
    "      with open(fname, 'r') as f:\n",
    "          last_line = f.readlines()[-1]\n",
    "          assert last_line in all_lines\n",
    "          \n",
    "  #check size and uniformity\n",
    "  total_size = os.stat(fname).st_size\n",
    "  uniform_part_size = total_size/n\n",
    "  chunk_size_list = []\n",
    "\n",
    "  for i in range(n):\n",
    "      file_name = fname + \"_\" + str(i).zfill(3)+\".txt\"\n",
    "      chunk_size = os.stat(file_name).st_size\n",
    "      chunk_size_list.append(chunk_size)\n",
    "      #difference is less than 10% of uniform size\n",
    "      assert abs(uniform_part_size - chunk_size) < 0.1*uniform_part_size\n",
    "\n",
    "  #check sum of chunk size is equal file size\n",
    "  assert sum(chunk_size_list) == total_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHOru_gDJJ8K"
   },
   "source": [
    "# Question 2 Encrypted Message\n",
    "We will implement a very simple encryption scheme that closely resembles the one-time-pad. You have probably seen this method used in movies like Unknown. The idea is that you and your counterparty share a book whose words you will use as the raw material for a codebook. In this case, you need Metamorphosis, by Franz Kafka.\n",
    "Your job is to create a codebook of 2-tuples that map to specific words in the given text based on the line and position the words appears in the text. The text is very long so there will be duplicated words. Strip out all of the punctuation and make everything lowercase.\n",
    "For example, the word let appears on line 1683 in the text as the fifth word (reading from left-to-right). Similarly, the word us appears in the text on line 1761 as the fifth word.\n",
    "Thus, if the message you want to send is the following:\n",
    "let us not say we met late at the night about the secret\n",
    "Then, one possible valid sequence for that message is the following:\n",
    "[(1394, 2), (1773, 11), (894, 10), (840, 1), (541, 2), (1192, 5), (1984, 7), (2112, 6), (1557, 2), (959, 8), (53, 10), (2232, 8), (552, 5)]\n",
    "Your counterparty receives the above sequence of tuples, and, because she has the same text, she is able to look up the line and word numbers of each of the tuples to retrieve the encoded message. Notice that the word the appears twice in the above message but is encoded differently each time. This is because re-using codewords (i.e., 2-tuples) destroys the encryption strength. In case of repeated words, you should have a randomized scheme to ensure that no message contains the same 2-tuple, even if the same word appears multiple times in the message. If there is only one occurrence of a word in the text and the message uses that word repeatedly so that each occurrence of the word cannot have a unique 2-tuple, then the message should be rejected (i.e., assert against this).\n",
    "Your assignment is to create an encryption function and the corresponding decryption function to implement this scheme. Note that your downloaded text should have 2362 lines and 25186 words in it.\n",
    "Here are the function signatures:\n",
    "```\n",
    "1 def encrypt_message(message,fname):\n",
    "2    '''\n",
    "3    Given `message`, which is a lowercase string without any punctuation, and `fname` which is the\n",
    "4    name of a text file source for the codebook, generate a sequence of 2-tuples that\n",
    "5    represents the `(line number, word number)` of each word in the message. The output is a list\n",
    "6    of 2-tuples for the entire message. Repeated words in the message should not have the same 2-tuple.\n",
    "7   \n",
    "8    :param message: message to encrypt\n",
    "9    :type message: str\n",
    "10    :param fname: filename for source text\n",
    "11    :type fname: str\n",
    "12    :returns: list of 2-tuples\n",
    "13    '''\n",
    "33 def decrypt_message(inlist,fname):\n",
    "34    '''\n",
    "35    Given `inlist`, which is a list of 2-tuples`fname` which is the\n",
    "36    name of a text file source for the codebook, return the encrypted message.\n",
    "37   \n",
    "38    :param message: inlist to decrypt\n",
    "39    :type message: list\n",
    "40    :param fname: filename for source text\n",
    "41    :type fname: str\n",
    "42    :returns: string decrypted message\n",
    "```\n",
    "Please put your Python code in a Python script file and upload it. Please retain your submitted source files! Remember to use all the best practices we discussed in class. You can use any module in the Python standard library, but third-party modules (e.g., Numpy, Pandas) are restricted to those explicitly mentioned in the problem description.\n",
    " \n",
    "After you have submitted your file, do not use the browser back or reload buttons to navigate or open the page in multiple browser tabs, as this may cause your attempts to decrease unexpectedly. It may take up to thirty seconds for your code to be processed, so please be patient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bR5PB2L-JJ8L"
   },
   "source": [
    "**Validation Tests** <br>\n",
    "Check for corner cases and constraints in the inputs enlist all cases used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7EPo6TJJJ8M"
   },
   "outputs": [],
   "source": [
    "# Validations for message\n",
    "assert isinstance(message, str), \"message must be a str\"\n",
    "assert len(message) > 0, \"message must not be empty\"\n",
    "assert message.lower()==message, \"message must be lowercase\"\n",
    "assert message.translate(str.maketrans('', '', string.punctuation))==message, \"message should not have punctuations\"\n",
    "\n",
    "# Validation for filename\n",
    "assert isinstance(fname, str), \"fname must be a str\"\n",
    "assert len(fname) > 0, \"fname must not be empty\"\n",
    "assert os.path.exists(fname) and os.path.isfile(fname), \"file must exist\"\n",
    "\n",
    "# Validations for inlist\n",
    "assert isinstance(inlist, list), \"inlist must be a list\"\n",
    "for item in inlist:\n",
    "    assert isinstance(item, tuple), \"list items must be tuples\"\n",
    "    assert len(item)==2, \"inlist tuples should have two elements\"\n",
    "    assert isinstance(item[0],int) and item[0]>=0, \"inlist tuples first element must be an integer\"\n",
    "    assert isinstance(item[1],int) and item[1]>=0, \"inlist tuples second element must be an integer\"\n",
    "\n",
    "\n",
    "# Make sure the message can actually be encoded using the dictionary file\n",
    "fwords = set()\n",
    "with open(fname, \"r\") as f:\n",
    "  fLines = f.readlines()\n",
    "  for line in fLines:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "      fwords.add(word)\n",
    "for word in message.split():\n",
    "  assert word in fwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYVUUbR7JJ8N"
   },
   "source": [
    "**Functional Tests** <br>\n",
    "Check function output matches expected result enlist all cases used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40ce0WjKJJ8N"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "messages = [\n",
    "  \"This is a secret message\",\n",
    "  \"\",\n",
    "  \"secret secret secret\",\n",
    "  \"let us night\",\n",
    "  \"secret about let say we met\"\n",
    "]\n",
    "fname = \"./pg5200.txt\"\n",
    "tuple_dict = {}\n",
    "    file = open(fname, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        words = line.split()\n",
    "        for word_idx, word in enumerate(words):\n",
    "            word = word.lower()\n",
    "            for ch in word:\n",
    "                if ch in punctuation:\n",
    "                    word = word.replace(ch, \"\")\n",
    "            tuple_dict[(line_num, word_idx)] = word\n",
    "for msg in messages:\n",
    "    tmp = encrypt_message(message, fname)\n",
    "    tuple_list = []\n",
    "    msg_words = msg.split()\n",
    "    for tuple_idx, tuple in enumerate(tmp):\n",
    "        ## checking the tuple is valid\n",
    "        assert tuple_dict[tuple] == msg_words[tuple_idx]\n",
    "        ## checking there's no repetition in the tuples\n",
    "        assert not tuple in tuple_list\n",
    "        tuple_list.append(tuple)\n",
    "\n",
    "\n",
    "# The encrypted message must be decrypted to original message\n",
    "assert decrypt_message(tmp, fname) == message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpyy98CVJJ8O"
   },
   "source": [
    "# Question 3 Multinomial Sampler\n",
    "Write a function to return samples from the Multinomial distribution using pure Python (i.e., no third-party modules like Numpy, Scipy). Here is some sample output.\n",
    "```\n",
    ">>> multinomial_sample(10,[1/3,1/3,1/3],k=10)\n",
    "[[3, 3, 4],\n",
    " [4, 4, 2],\n",
    " [3, 4, 3],\n",
    " [5, 2, 3],\n",
    " [3, 3, 4],\n",
    " [3, 4, 3],\n",
    " [6, 2, 2],\n",
    " [2, 6, 2],\n",
    " [5, 4, 1],\n",
    " [4, 4, 2]]\n",
    " ```\n",
    "Here is your function signature\n",
    "```\n",
    "def multinomial_sample(n,p,k=1): \n",
    "        '''                                                                \n",
    "        Return samples from a multinomial distribution.                    \n",
    "                                                                           \n",
    "        n:= number of trials                                               \n",
    "        p:= list of probabilities                                          \n",
    "        k:= number of desired samples                                      \n",
    "        '''                                                                \n",
    " ```\n",
    "Please keep the default values as given in the function signature.\n",
    "\n",
    "Please put your Python code in a Python script file and upload it. Please retain your submitted source files! Remember to use all the best practices we discussed in class. You can use any module in the Python standard library, but third-party modules (e.g., Numpy, Pandas) are restricted to those explicitly mentioned in the problem description.\n",
    " \n",
    "After you have submitted your file, do not use the browser back or reload buttons to navigate or open the page in multiple browser tabs, as this may cause your attempts to decrease unexpectedly. It may take up to thirty seconds for your code to be processed, so please be patient.\n",
    " \n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvvRqggEJJ8O"
   },
   "source": [
    "**Validation Tests** <br>\n",
    "Check for corner cases and constraints in the inputs enlist all cases used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwIGWoFxJJ8P"
   },
   "outputs": [],
   "source": [
    "assert isinstance(n, int), \"n must be int\"\n",
    "assert isinstance(p, list), \"p must be list\"\n",
    "assert isinstance(k, int), \"k must be int\"\n",
    "assert len(p)>=1, \"The distribution must be non-empty to be able to sample from it\"\n",
    "assert n > 0 and k > 0, \"sample and trials must be greater than zero\"\n",
    "for prob in p:\n",
    "    assert isinstance(prob, int) or isinstance(prob,float), \"elements in p must be either int or float\"\n",
    "    assert 0<=prob<=1, \"probability must be between 0 and 1\"\n",
    "assert abs(sum(p)-1)<=1e-9, \"probabilities in p must sum to 1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlgBFYIQJJ8P"
   },
   "source": [
    "**Functional Tests** <br>\n",
    "Check function output matches expected result enlist all cases used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGEFiaHhJJ8P"
   },
   "outputs": [],
   "source": [
    "# Check basic outputs for variety of cases (not checking sample statistics here)\n",
    "ns = [1,5,10]\n",
    "ps = [[1,0,0],[1/3,1/3,1/3],[1/4,1/2,1/4], [1], [0.5,0.5]]\n",
    "ks = [1,3,5]\n",
    "for n in ns:\n",
    "  for k in ks:\n",
    "    for p in ps:\n",
    "      res = multinomial_sample(n,p,k)\n",
    "      # Length of result must be of size k\n",
    "      assert isinstance(res, list), \"The result must be a list of lists\"\n",
    "      assert len(res) == k, \"The result must have a length k\"\n",
    "      for ele in res:\n",
    "          assert isinstance(ele, list), \"The result must be a list of lists\"\n",
    "          assert len(ele) == len(p), \"Each sample must be of length of probability distribution\"\n",
    "          assert sum(ele) == n, \"Total numberof outcomes must be equal to n for each sample\"\n",
    "\n",
    "          # Corner case check when distribution has a single support\n",
    "          if p == [1,0,0]:\n",
    "              assert elem[0] == n, \"If p=[1,0,0], then all outcomes must be 0\"\n",
    "          if p == [0,1,0]:\n",
    "              assert elem[2] == n, \"If p=[0,1,0], then all outcomes must be 1\"\n",
    "          if p == [0,0,1]:\n",
    "              assert elem[2] == n, \"If p=[0,0,1], then all outcomes must be 2\"\n",
    "\n",
    "\n",
    "# Statistics Check - Mean and variance should correspond to input distribution over 10000 samples within a 5 percent tolerance\n",
    "import numpy as np\n",
    "ns = [5,10]\n",
    "ps = [[1,0,0],[1/4,1/2,1/4],[1/3,1/3,1/3]]\n",
    "k = 10000\n",
    "tolerance = 0.05 # 5 percent tolerance in the mean and variance\n",
    "for n in ns:\n",
    "  for p in ps:\n",
    "    res = multinomial_sample(n,p,k)\n",
    "    res = np.array(res)\n",
    "    assert res.shape[0]==k, \"K samples must be generated\"\n",
    "    assert res.shape[1]==len(p), \"Each sample must be of length of probability distribution\"\n",
    "    prob_dis = np.array(p)\n",
    "    expected_mean = n*prob_dis\n",
    "    expected_var = n*prob_dis*(1-prob_dis)\n",
    "    res_mean = res.mean(0) \n",
    "    res_var = res.var(0)\n",
    "    assert np.sum(np.absolute(res_mean-expected_mean)) < np.sum(np.absolute(tolerance*expected_mean), \"Over 10k samples, expected mean is deviating\"\n",
    "    assert np.sum(np.absolute(res_var-expected_var)) < np.sum(np.absolute(tolerance*expected_var), \"Over 10k samples, expected variance is deviating\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "colab": {
   "name": "Group18_Assignment6 (1) (1).ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
